{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python | Pytorch | OpenCV versions: 3.7.0 (default, Jun 28 2018, 13:15:42) \n",
      "[GCC 7.2.0] | 0.4.1 | 3.4.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "from importlib import reload\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "print('Python | Pytorch | OpenCV versions: %s | %s | %s' %(sys.version, torch.__version__, cv2.__version__))\n",
    "\n",
    "sys.path.append('/home/blanca/mnt/projects/')\n",
    "import tools\n",
    "from tools.utils import *\n",
    "from tools.visuals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 7711)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns_file = '/home/blanca/mnt/data/__toy_plane/annotations/annotations_classes_attbs_body_drill.json'\n",
    "\n",
    "with open(anns_file, 'r') as f: anns_dataset = json.load(f)\n",
    "len(anns_dataset['images']), len(anns_dataset['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from skimage import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "class Resize(object):\n",
    "    def __init__(self, new_dims):\n",
    "        if isinstance(new_dims, int): self.dims = (new_dims, new_dims)\n",
    "        else: self.dims = new_dims\n",
    "    def resize_image(self, im):\n",
    "        return cv2.resize(im, (self.dims))\n",
    "    def __call__(self, im):\n",
    "        return self.resize_image(im)\n",
    "\n",
    "def bbcc_from_xxww(boxes):\n",
    "    assert boxes.shape[1] == 4\n",
    "    cc = np.zeros((boxes.shape[0], 2))\n",
    "    cc[:, 0] = boxes[:, 0] + boxes[:, 2] / 2\n",
    "    cc[:, 1] = boxes[:, 1] + boxes[:, 3] / 2\n",
    "    return cc.astype(np.int32)\n",
    "\n",
    "def resize_angle(ang, input_size, target_size):\n",
    "    sx, sy = target_size[1] / input_size[1], target_size[0] / input_size[0]\n",
    "    sin, cos = np.sin(ang) * sy, np.cos(ang) * sx\n",
    "    angr = np.arctan2(sin, cos)\n",
    "    return angr\n",
    "\n",
    "def resize_xxyy_bboxs(bboxs, input_size, target_size):\n",
    "    ws = target_size[1] / input_size[1]\n",
    "    hs = target_size[0] / input_size[0]\n",
    "    # print('HERE:', input_size, target_size, ws, hs, bboxs)\n",
    "    bboxsr = np.zeros_like(bboxs)\n",
    "    bboxsr[:,0], bboxsr[:,2] = bboxs[:,0] * ws, bboxs[:,2] * ws\n",
    "    bboxsr[:,1], bboxsr[:,3] = bboxs[:,1] * hs, bboxs[:,3] * hs\n",
    "    return bboxsr\n",
    "\n",
    "def ulbr_to_ulwh(boxes):\n",
    "    \"\"\"\n",
    "    From upper | left | bottom | right to upper | left | w | h\n",
    "    \"\"\"\n",
    "    nboxes = np.zeros(boxes.shape, dtype=np.int32)\n",
    "    nboxes[:, 0] = boxes[:, 0]\n",
    "    nboxes[:, 1] = boxes[:, 1]\n",
    "    nboxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "    nboxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "    return nboxes\n",
    "\n",
    "def resize_bbccs_for_vis(bbccs, input_size, target_size):\n",
    "    ws = target_size[1] / input_size[1]\n",
    "    hs = target_size[0] / input_size[0]\n",
    "    bbcsr = np.zeros_like(bbccs)\n",
    "    bbcsr[0], bbcsr[1]  = bbccs[0] * ws, bbccs[1] * hs\n",
    "    return bbcsr\n",
    "    \n",
    "class VectorDataset(Dataset):\n",
    "    def __init__(self, CF, mode):\n",
    "        super(VectorDataset).__init__()\n",
    "        \"\"\"\n",
    "        'i', 'l' in variable names stand for input and label respectively\n",
    "        \"\"\"\n",
    "        self.CF = CF\n",
    "\n",
    "        input_dir=Path(CF.input_dir) if CF.input_dir else None\n",
    "        data_dir=Path(CF.data_dir) if CF.data_dir else None\n",
    "\n",
    "        # if data.pickle file available, load:\n",
    "        if not data_dir: \n",
    "            print('Provide a \"data_dir\" in the .yaml file to store the .pickle files')\n",
    "            return\n",
    "        \n",
    "        pickle_file = list(data_dir.glob(input_dir.name + '_data.pickle'))\n",
    "        print('************ ', pickle_file)\n",
    "        if len(pickle_file) == 1:\n",
    "            pickle_file = pickle_file[0]\n",
    "            print('Loading %s file as dataset ' %pickle_file)\n",
    "            with open(str(pickle_file), 'rb') as data: dataset = pickle.load(data)\n",
    "        else: \n",
    "            print('No .pickle file available @%s  |  Loading dataset from input_dir %s' %(data_dir, input_dir))\n",
    "            assert input_dir is not None\n",
    "\n",
    "            ims_dir = input_dir / 'JPEGImagesDV_9009'\n",
    "            anns_dir = input_dir / 'annotations/annotations_9009_with_directions.json'\n",
    "\n",
    "            with open(anns_dir, 'r') as f: anns_dataset = json.load(f)\n",
    "\n",
    "            # create dataset and shuffle \n",
    "            dataset = {}\n",
    "            count_ims = 0\n",
    "            count_nf_ims = 0\n",
    "            for imo in anns_dataset['images']:\n",
    "                iid, url = imo['id'], imo['coco_url']\n",
    "                anns = [ao for ao in anns_dataset['annotations'] if ao['image_id'] == iid] #and ao['angle'] is not None] \n",
    "                if len(anns) == 0: print('anns empty - double check', iid, url); break\n",
    "                # try: \n",
    "                if True:\n",
    "                    # print('Reading %s from disk: ' %imo['file_name'], end='')\n",
    "                    im = cv2.imread(str(ims_dir / (imo['file_name'].split('.png')[0] + '.jpg')))\n",
    "                    if im is None: \n",
    "                        count_nf_ims += 1\n",
    "                        continue\n",
    "                    dataset[iid] = {'url': url, \n",
    "                                    'im': im,\n",
    "                                    'ann': anns,\n",
    "                                }\n",
    "                    count_ims += 1\n",
    "                # except: print('Not able to request image at %s | read images: %d' %(url, count_ims))\n",
    "            print('Not able to found %d images' %count_nf_ims)\n",
    "\n",
    "            with open(str(data_dir / (input_dir.name + '_data.pickle')), 'wb') as output: pickle.dump(dataset, output)\n",
    "            print('Saved full dataset @%s, pickle it next time' %data_dir)\n",
    "\n",
    "            assert len(dataset) == len(np.unique(list(dataset.keys())))\n",
    "\n",
    "        # shuffle and split data\n",
    "        np.random.seed(13)\n",
    "        overfit = isinstance(CF.overfit, int) # dataset size to overfit\n",
    "        if overfit: \n",
    "            ss_ix = [list(dataset.keys())[i] for i in np.random.permutation(CF.overfit)]\n",
    "            ss_ixs = {'train': ss_ix}\n",
    "        else: \n",
    "            ss_ix = [list(dataset.keys())[i] for i in np.random.permutation(len(dataset))]\n",
    "            split_ix = int((len(ss_ix) / CF.batch_size) // 5) * CF.batch_size\n",
    "            ss_ixs = {'train': ss_ix[split_ix:], 'eval': ss_ix[:split_ix]}\n",
    "        \n",
    "        self.dataset = {i: j for i, j in dataset.items() if i in ss_ixs[mode]}\n",
    "        # print('Check: ', assert [i not in ss_ixs['train'] for i in ss_ixs['eval']])\n",
    "\n",
    "        self.n_obs_per_im = CF.n_obs_per_im\n",
    "        # self.label_size = self.n_obs_per_im * 2 # assume 50 objects per image\n",
    "        print('Initialized \"%s\" dataset with %d images-label pairs' %(mode, len(self.dataset)))\n",
    "        \n",
    "        # if overfit: [print(self.dataset[ix]['url']) for ix in list(self.dataset.keys())]\n",
    "\n",
    "        # apply transforms to image and labels\n",
    "        # self.transforms = ['resize'] #[RandomCrop(512)]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        it = time.time()\n",
    "        \n",
    "        d_ix = list(self.dataset.keys())[index] # ix. for the dictionary  \n",
    "        im = self.dataset[d_ix]['im']\n",
    "        anns = self.dataset[d_ix]['ann'] \n",
    "        url = self.dataset[d_ix]['url']\n",
    "\n",
    "        model_input_size = self.CF.input_size\n",
    "        # color_list = colormap(rgb=True) / 255\n",
    "        # angs = [random.randint(0, 360) for i in range(len(anns))]\n",
    "        \n",
    "        # bboxes & labels \n",
    "        bboxs = np.array([ann['bbox'] for ann in anns])\n",
    "        angs = np.array([ann['angle'] for ann in anns])\n",
    "        ## order from left to right\n",
    "        \n",
    "        order_ix = bboxs[:,0].argsort()\n",
    "        bboxs = bboxs[order_ix]\n",
    "        angs = angs[order_ix]\n",
    "        \n",
    "        ## pad with zeros\n",
    "        bboxs = np.pad(bboxs, [(0, self.n_obs_per_im - bboxs.shape[0]), (0, 0)], mode='constant', constant_values=0) #bboxs[:a.shape[0], :a.shape[1]] = 0\n",
    "        angs = np.pad(angs, [(0, self.n_obs_per_im - len(angs))], mode='constant', constant_values=0)\n",
    "\n",
    "        ## save originals before risizing - used if decoding\n",
    "        bboxs_ = bboxs.copy() \n",
    "        angs_ = angs.copy()\n",
    "        im_ = im.copy()\n",
    "\n",
    "        ## resize\n",
    "        if im.shape[:2] != model_input_size:\n",
    "            angs = np.array([resize_angle(ang, im.shape, model_input_size) for ang in angs])\n",
    "            bboxs = resize_xxyy_bboxs(bboxs[:, :4], im.shape, model_input_size)\n",
    "            im = cv2.resize(im, (model_input_size[1], model_input_size[0]))\n",
    "        # bboxes centres\n",
    "        bbccs = bbcc_from_xxww(bboxs[:, :4])\n",
    "\n",
    "        ## add a fourth channel with the bbox centre points\n",
    "        input_nc = self.CF.input_nc\n",
    "        if input_nc == 3: \n",
    "            for bbcc in bbccs: \n",
    "                if bbcc[0] == 0 and bbcc[1] == 0: continue\n",
    "                cv2.circle(im, (int(bbcc[0]), int(bbcc[1])), 5, (255, 255, 255), -1)\n",
    "        elif input_nc == 4:\n",
    "            imcc = np.expand_dims(np.zeros(im.shape[:2]), axis=2)\n",
    "            for bbcc in bbccs: \n",
    "                if bbcc[0] == bbcc[1] == 0: continue\n",
    "                cv2.circle(imcc, (int(bbcc[0]), int(bbcc[1])), 2, (255, 255, 255), -1)\n",
    "            if self.CF.provide_bbox:\n",
    "                for bbox in bboxs:\n",
    "                    if bbox[0] == bbox[1] == bbox[2] == bbox[3] == 0: continue\n",
    "                    bbox = [int(i) for i in bbox]\n",
    "                    x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "                    cv2.rectangle(imcc, (x, y), (x + w, y + h), (255, 255, 255), 1)\n",
    "            im = np.concatenate((im, imcc), axis=2)\n",
    "\n",
    "        # LABEL: 1D ARRAY (MODEL: ENCODER)\n",
    "        if not self.CF.decoder:\n",
    "            assert self.CF.predict_centre\n",
    "            # print('Using encoder.. ')\n",
    "\n",
    "            n_ob = 0\n",
    "            lab = np.zeros(4 * self.n_obs_per_im)\n",
    "            for _, (bbcc, ang) in enumerate(zip(bbccs, angs)):\n",
    "                if bbcc[0] == 0.0 and bbcc[1] == 0.0 and ang == 0.0: continue\n",
    "                if self.CF.predict_score: \n",
    "                    lab[n_ob*4], lab[n_ob*4 + 1], lab[n_ob*4 + 2], lab[n_ob*4 + 3], lab[n_ob*4 + 4]  = np.ones(1), bbcc[0], bbcc[1], np.sin(ang), np.cos(ang)\n",
    "                else: \n",
    "                    lab[n_ob*4], lab[n_ob*4 + 1], lab[n_ob*4 + 2], lab[n_ob*4 + 3] = bbcc[0], bbcc[1], np.sin(ang), np.cos(ang)\n",
    "                n_ob += 1\n",
    "\n",
    "            n_ob = 0\n",
    "            mask = np.zeros(4 * self.n_obs_per_im)\n",
    "            for _, bbcc in enumerate(bbccs):\n",
    "                if bbcc[0] == 0.0 and bbcc[1] == 0.0: continue\n",
    "                mask[n_ob*4 : n_ob*4 + 4] = np.ones(4)\n",
    "            n_ob += 1\n",
    "\n",
    "        # else: \n",
    "            # lab = np.zeros(2 * self.n_obs_per_im)\n",
    "            # for _, ang in enumerate(angs):\n",
    "            #     if bbcc[0] == 0.0 and bbcc[1] == 0.0 and ang == 0.0: continue\n",
    "            #     lab[_*2], lab[_*2 + 1] = np.sin(ang), np.cos(ang)\n",
    "\n",
    "        # LABEL: 3D ARRAY (MODEL: AUTOENCODER)\n",
    "        else:\n",
    "            assert not self.CF.predict_centre\n",
    "            # print('Using autoencoder.. ')\n",
    "\n",
    "            ## 1. resize for label\n",
    "            model_output_size = self.CF.output_size\n",
    "            if im_.shape[:2] != model_output_size:\n",
    "                angso = np.array([resize_angle(ang_, im_.shape, model_output_size) for ang_ in angs_])\n",
    "                bboxso = resize_xxyy_bboxs(bboxs_[:, :4], im_.shape, model_output_size)\n",
    "                imo = cv2.resize(im_, (model_output_size[1], model_output_size[0]))\n",
    "            \n",
    "            \"\"\"check\"\"\"\n",
    "            assert model_output_size == model_input_size\n",
    "            assert (angso == angs).all()\n",
    "            assert (bboxso == bboxs).all()\n",
    "            # assert (imo == im).all()\n",
    "            # print(imo, im)\n",
    "\n",
    "            bbccso = bbcc_from_xxww(bboxso[:, :4])\n",
    "            \n",
    "            # fill label\n",
    "            lab = np.zeros((model_output_size[0], model_output_size[1], self.CF.output_nc))\n",
    "            for _, (bbcco, ango) in enumerate(zip(bbccso, angso)):\n",
    "                \"Label of output_size with sin, cos in the centre of the object bounding box\"\n",
    "                if bbcco[0] == 0.0 and bbcco[1] == 0.0 and ango == 0.0: continue\n",
    "                lab[bbcco[1], bbcco[0], 0] = np.sin(ango)\n",
    "                lab[bbcco[1], bbcco[0], 1] = np.cos(ango)\n",
    "                if self.CF.predict_score: lab[bbcco[1], bbcco[0], 2] = np.ones(1) \n",
    "            \n",
    "            mask = np.zeros((model_output_size[0], model_output_size[1]))\n",
    "            for _, bbcco in enumerate(bbccso):\n",
    "                if bbcco[0] == 0.0 and bbcco[1] == 0.0: continue\n",
    "                mask[bbcco[1], bbcco[0]] = np.ones(1)                 \n",
    "\n",
    "            # if self.CF.predict_score: lab = np.concatenate((lab, np.expand_dims(mask, axis=2)), axis=2)\n",
    "\n",
    "        input_im = Variable(torch.Tensor(np.transpose(im, (2,0,1)) / 255.))\n",
    "        input_lb = Variable(torch.Tensor(lab)) if not self.CF.decoder else Variable(torch.Tensor(np.transpose(lab, (2,0,1))))\n",
    "        mask = Variable(torch.Tensor(mask))\n",
    "\n",
    "        # print(input_lb[2,:,:].shape, mask.shape, (input_lb[2,:,:] == mask).all())\n",
    "\n",
    "        return input_im, input_lb, bboxs, bbccs, url, angs, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "def save_input_image(im, bboxs, bbccs, angs, vis_size):\n",
    "    imc = im.copy()\n",
    "    \n",
    "    if im.shape[:2] != vis_size:\n",
    "        bboxs = resize_xxyy_bboxs(bboxs[:, :4], im.shape, vis_size)\n",
    "        bbccs = bbcc_from_xxww(bboxs[:, :4])\n",
    "        im = cv2.resize(im, (vis_size[1], vis_size[0]))\n",
    "    \n",
    "    im = np.ascontiguousarray(im*255, dtype=np.int32)\n",
    "\n",
    "    for bbox in bboxs:\n",
    "        bbox = [int(i) for i in bbox]\n",
    "        x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "        cv2.rectangle(imc, (x, y), (x + w, y + h), (255, 0, 0), 10)\n",
    "\n",
    "    for _, (bbcc, ang) in enumerate(zip(bbccs, angs)):\n",
    "        cv2.addText(im, 'bb_%d' %_, (bbcc[0], bbcc[1]))\n",
    "        \n",
    "    cv2.imwrite(im, 'input_sample.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
